{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54eabc84-d793-4183-920d-ac4f20ab2902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in /opt/conda/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: faker in /opt/conda/lib/python3.11/site-packages (37.1.0)\n",
      "Requirement already satisfied: tzdata in /opt/conda/lib/python3.11/site-packages (from faker) (2023.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish\n",
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fa1b45-7b04-4cc2-a017-5cfbf9ffec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "import math\n",
    "from itertools import combinations, product\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "from packages.generateDataSets import SyntheticMatcherDataset\n",
    "from packages.calculateStatistics import DatasetEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263d1dfd-42da-463a-9eed-86cf9556e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, df1: pd.DataFrame, \n",
    "                 df2: pd.DataFrame, \n",
    "                 matchColumn: str, \n",
    "                 on: List = [],\n",
    "                 method: str = 'column', \n",
    "                 threshold: float  = 0.6):\n",
    "        self.df1 = df1\n",
    "        self.df2 = df2\n",
    "        self.on = on\n",
    "        self.threshold = threshold\n",
    "\n",
    "        if method not in [\"concat\", \"column\"]:\n",
    "            raise ValueError(f\"Method '{method}' is not correct.\")\n",
    "        self.method = method\n",
    "\n",
    "    \n",
    "        if matchColumn not in self.df1.columns or matchColumn not in self.df2.columns:\n",
    "            raise ValueError(f\"Column '{matchColumn}' is not found in both DataFrames.\")\n",
    "        self.matchColumn = matchColumn\n",
    "        \n",
    "        self.groundTruth = None\n",
    "        self.totalMatches = None        \n",
    "    \n",
    "    def setGroundTruth(self):\n",
    "        \"\"\"Sets the ground truth based on matching 'id' columns.\"\"\"\n",
    "        self.groundTruth = np.intersect1d(self.df1[self.matchColumn], self.df2[self.matchColumn])\n",
    "\n",
    "    def soundexDfs(self):\n",
    "        \"\"\"Apply soundex transformation to non-id columns.\"\"\"\n",
    "        for df in [self.df1, self.df2]:\n",
    "            for col_name in df.columns:\n",
    "                if col_name != self.matchColumn:\n",
    "                    df[col_name] = df[col_name].apply(lambda x: jellyfish.soundex(str(x)))\n",
    "\n",
    "            if self.method == 'concat':\n",
    "                non_match_columns = [col for col in df.columns if col != self.matchColumn]\n",
    "                df['concatenated'] = df[non_match_columns].apply(lambda row: ''.join(row.astype(str)), axis=1)\n",
    "                df.drop(columns=non_match_columns, inplace=True)\n",
    "\n",
    "    def setTotalMatches(self):\n",
    "        \"\"\"Sets the total matches based on merged DataFrames.\"\"\"\n",
    "        \n",
    "        # if self.method == 'concat':\n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"inner\", on=['concatenated']).to_numpy()\n",
    "        # else:   \n",
    "        #     self.totalMatches = self.df1.merge(self.df2, how=\"outer\", on=self.on + [self.matchColumn]).to_numpy()\n",
    "\n",
    "        self.totalMatches =  self.df1.merge(pd.concat([self.df1, self.df2]), how='outer', on=self.on)[[\"0_y\"] + self.on]\n",
    "        self.totalMatches.rename(columns={'0_y': self.matchColumn}, inplace=True)\n",
    "        \n",
    "    def printStatistics(self):\n",
    "        \"\"\"Print statistics (True Positives, False Positives, Precision).\"\"\"\n",
    "        myStatistics = self.Statistics(groundTruth=self.groundTruth, \n",
    "                                       totalMatches=self.totalMatches, \n",
    "                                       threshold=self.threshold, \n",
    "                                       on=self.on, \n",
    "                                       matchColumn=self.matchColumn)\n",
    "        myStatistics.calculate()\n",
    "\n",
    "    # Inner class Statistics\n",
    "    class Statistics:\n",
    "        def __init__(self,\n",
    "                     groundTruth: pd.DataFrame, \n",
    "                     totalMatches: pd.DataFrame, \n",
    "                     threshold : float = 0.8,\n",
    "                     matchColumn: str | int = 1,\n",
    "                     on: List =[]):\n",
    "            self.groundTruth = pd.DataFrame(groundTruth)\n",
    "            self.totalMatches = pd.DataFrame(totalMatches)\n",
    "            self.threshold = threshold\n",
    "            self.matchColumn = matchColumn\n",
    "            self.on = on\n",
    "\n",
    "            self._setThresholdValues()\n",
    "            \n",
    "        def calculate(self):\n",
    "            # self.result = self.totalMatches.groupby(self.matchColumn)\\\n",
    "            #         .filter(lambda x : len(x) >=2)\\\n",
    "            #         .groupby(self.matchColumn)\\\n",
    "            #         .apply(lambda x: x.iloc[:, 1:].apply(lambda x: x.nunique() == 1)).sum(axis=1)\n",
    "\n",
    "            duplicates = self.totalMatches[self.totalMatches[[1,2,3,4,5]].duplicated(keep=False)].sort_values(by=[1,2,3,4,5])\n",
    "        \n",
    "            # Function to check if two rows match at least 3/5 columns\n",
    "            def is_duplicate(row1, row2):\n",
    "                return sum(row1 == row2) >=  self.matchingRows  # At least 3 matches out of 5\n",
    "\n",
    "            # print(duplicates)\n",
    "            \n",
    "            duplicate_pairs = []\n",
    "            # Find duplicates\n",
    "            for i in range(len(duplicates)):\n",
    "                for j in range(i + 1, len(duplicates)):  # Compare only unique pairs\n",
    "                    if is_duplicate(duplicates.iloc[i, 1:], duplicates.iloc[j, 1:]):\n",
    "                        duplicate_pairs.append((i, j, duplicates.iloc[i, 0] == duplicates.iloc[j, 0]))  # Store (index1, index2, same_id)\n",
    "\n",
    "            # Count same ID and different ID duplicates\n",
    "            tp = sum(1 for _, _, same_id in duplicate_pairs if same_id)\n",
    "            fp = len(duplicate_pairs) - same_id_count\n",
    "            fn = self.groundTruth.size - tp\n",
    "            \n",
    "            precision = tp / (tp + fp) if tp + fp != 0 else 0 \n",
    "            recall = tp / (tp + fn)  if tp + fn != 0 else 0\n",
    "            f1_score = (2 * precision * recall) / (precision + recall)\n",
    "            \n",
    "            print(\"Total Possible Mathces:\", self.groundTruth.size)\n",
    "            print(\"True Positives (TP):\", tp)\n",
    "            print(\"False Positives (FP):\", fp)\n",
    "            print(\"False Negatives (FN):\", fn)\n",
    "            print(\"Precision:\", f\"{precision:.4f}\")\n",
    "            print(\"Recall:\", f\"{recall:.4f}\")\n",
    "            print(\"F1-score:\", f\"{f1_score:.4f}\")\n",
    "\n",
    "        def _matchingAlgorithm(self, group):\n",
    "            return group.nunique() == 1\n",
    "            \n",
    "        def _setThresholdValues(self) -> List:\n",
    "            size = len(self.totalMatches.columns) - 1\n",
    "            limit = math.floor(self.threshold * size)\n",
    "            \n",
    "            print(f\"We accept at least {limit}/{size} as matches!\") \n",
    "            self.matchingRows = limit\n",
    "            # return [i for i in range(size, limit , -1)]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d804a1c-5175-4398-b9a5-30b12ac8386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df2.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df3 = pd.read_csv(os.path.join(PATH, 'df3.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df4 = pd.read_csv(os.path.join(PATH, 'df4.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df5 = pd.read_csv(os.path.join(PATH, 'df5.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "\n",
    "df1, df2 = pipeline.df1.copy(), pipeline.df2.copy()\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df3, df4, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "\n",
    "df3, df4 = pipeline.df1.copy(), pipeline.df2.copy()\n",
    "\n",
    "pipeline = MyClass(df1.copy(), df5, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "\n",
    "df5 = pipeline.df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12492b90-54e7-4707-9c6d-cf1070265fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: {}\n",
      "Ground Truth Size: 25000\n",
      "True Positives: 19036\n",
      "False Positives: 17830\n",
      "False Negatives: 5964\n",
      "Precision: 0.5164\n",
      "Recall: 0.7614\n",
      "Elapsed Time: 33682.16 seconds\n"
     ]
    }
   ],
   "source": [
    "evaluator = DatasetEvaluator(pipeline.df1, pipeline.df2, threshold=3)\n",
    "evaluator.evaluate()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7754327-ae4f-483b-a4d2-3e40e677ee99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.356155555555556"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33682.16/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3013db6-b66b-491b-bfe2-d07daf5e4a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 19036\n",
    "False Positives: 17830\n",
    "False Negatives: 5964\n",
    "Precision: 0.5164\n",
    "Recall: 0.7614\n",
    "Elapsed Time: 33682.16 seconds\n",
    "\n",
    "# df1 -> df2\n",
    "thresh = 3\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 19036\n",
    "False Positives: 17830\n",
    "False Negatives: 5964\n",
    "Precision: 0.5164\n",
    "Recall: 0.7614\n",
    "Elapsed Time: 81137.75 seconds\n",
    "\n",
    "\n",
    "# df1 -> df5\n",
    "thresh = 2\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 24977\n",
    "False Positives: 74055\n",
    "False Negatives: 23\n",
    "Precision: 0.2522\n",
    "Recall: 0.9991\n",
    "Elapsed Time: 4861.54 seconds\n",
    "\n",
    "# df1 -> df5\n",
    "thresh = 3\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 19125\n",
    "False Positives: 16323\n",
    "False Negatives: 5875\n",
    "Precision: 0.5395\n",
    "Recall: 0.7650\n",
    "Elapsed Time: 80256.47 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a3d4cf-36e3-4b0e-96eb-5f4923a1274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import jellyfish\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import os\n",
    "import math\n",
    "from itertools import combinations, product\n",
    "import time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from collections import defaultdict\n",
    "from packages.generateDataSets import SyntheticMatcherDataset\n",
    "from packages.calculateStatistics import DatasetEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6b22753-5166-46e7-b4d2-b0875bc3e1e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1, 2, 3, 4, 5], threshold=0.4)\n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "pipeline.setTotalMatches()\n",
    "# pipeline.printStatistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e61a9ab-5dfa-42af-930f-5322c13c0b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best column triplet (least unique values): (1, 4, 5)\n",
      "Number of unique combinations: 77477\n"
     ]
    }
   ],
   "source": [
    "PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df2.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1, df2, matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.setGroundTruth()\n",
    "pipeline.soundexDfs()\n",
    "\n",
    "\n",
    "columns = [1,2,3,4,5]\n",
    "\n",
    "# Store result as (column_triplet, unique_count)\n",
    "unique_counts = []\n",
    "for cols in combinations(columns, 3):\n",
    "    count = df2[list(cols)].agg(''.join, axis=1).nunique()\n",
    "    unique_counts.append((cols, count))\n",
    "\n",
    "# Find the combination with the minimum unique count\n",
    "best_combination = min(unique_counts, key=lambda x: x[1])\n",
    "\n",
    "print(\"Best column triplet (least unique values):\", best_combination[0])\n",
    "print(\"Number of unique combinations:\", best_combination[1])\n",
    "\n",
    "# evaluator = DatasetEvaluator(pipeline.df1, pipeline.df2, expected, threshold=3)\n",
    "# evaluator.evaluate()\n",
    "# evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37fcd5ed-4335-4743-84b1-f40ee90eb084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 4, 5), 77477)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417a7d24-9413-4a66-9007-b0000707ef6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.293463888888887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80256.47/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9daaaf29-2c59-4fef-875d-9d579ffc1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3, df4 = pipeline.df1, pipeline.df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22a4547-5419-4190-b7a9-56f3d8820988",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedData = pd.concat([df2]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272e7229-d9ac-4e5f-b36b-d5a4b4786a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproccess took 5.5582 seconds\n",
      "evaluate took 111.8659 seconds\n",
      "calculateStatistics took 0.0077 seconds\n",
      "Expected: {}\n",
      "Ground Truth Size: 271\n",
      "True Positives: 202\n",
      "False Positives: 248\n",
      "False Negatives: 69\n",
      "Precision: 0.4489\n",
      "Recall: 0.7454\n"
     ]
    }
   ],
   "source": [
    "evaluator = DatasetEvaluator(df1.sample(frac=0.01, random_state=42), matchedData, threshold=3)\n",
    "evaluator.preproccess()\n",
    "evaluator.evaluate()\n",
    "evaluator.calculateStatistics()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38872e35-1e09-4417-bec4-bc84315f8a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproccess took 8.6420 seconds\n",
    "evaluate took 134.6332 seconds\n",
    "calculateStatistics took 0.0088 seconds\n",
    "Expected: {}\n",
    "Ground Truth Size: 271\n",
    "True Positives: 202\n",
    "False Positives: 248\n",
    "False Negatives: 69\n",
    "Precision: 0.4489\n",
    "Recall: 0.7454\n",
    "\n",
    "preproccess took 8.0907 seconds\n",
    "evaluate took 140.7979 seconds\n",
    "calculateStatistics took 0.3955 seconds\n",
    "Expected: {}\n",
    "Ground Truth Size: 271\n",
    "True Positives: 202\n",
    "False Positives: 248\n",
    "False Negatives: 69\n",
    "Precision: 0.4489\n",
    "Recall: 0.7454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e5a1b-23d4-40ca-8122-7444c411a33c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproccess took 29.9362 seconds\n"
     ]
    }
   ],
   "source": [
    "matchedData = pd.concat([df2, df3, df4, df5]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "evaluator = DatasetEvaluator(df1, matchedData, threshold=3, trim=0)\n",
    "evaluator.preproccess()\n",
    "evaluator.evaluate()\n",
    "evaluator.calculateStatistics()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae519f3-3d1f-42b6-9f01-1e86e9bd670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproccess took 28.2823 seconds\n",
    "evaluate took 17617.6667 seconds\n",
    "calculateStatistics took 0.5669 seconds\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 21695\n",
    "False Positives: 18613\n",
    "False Negatives: 3305\n",
    "Precision: 0.5382\n",
    "Recall: 0.8678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0195bf2-4835-458d-862d-c85baf424ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3191df3-0688-4818-9be5-b80b3c4cf249",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1.merge(df2, how=\"outer\").merge(df3, how=\"outer\").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a64f105c-befd-4e85-b927-48ac5b5d74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchedData = pd.concat([df2, df3, df4, df5]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd728ef-301d-4090-a936-07066605afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6833, 18, 18167, 0.997372646329003, 0.27332)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.merge(matchedData, on=[1,2,3,4,5], how='inner')\n",
    "gt = np.intersect1d(df1[0], matchedData[0]).size\n",
    "\n",
    "tp = (result['0_x'] == result['0_y']).sum()\n",
    "fn = gt - tp\n",
    "fp = (result['0_x'] != result['0_y']).sum()\n",
    "\n",
    "tp, fp, fn, tp/(tp+fp), tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca7169b-d6cd-4c51-a0b3-74ebd9bf0f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA100000</td>\n",
       "      <td>B323</td>\n",
       "      <td>J520</td>\n",
       "      <td>A620</td>\n",
       "      <td>3523</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA100004</td>\n",
       "      <td>B620</td>\n",
       "      <td>M240</td>\n",
       "      <td>E421</td>\n",
       "      <td>2251</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA100006</td>\n",
       "      <td>B620</td>\n",
       "      <td>D520</td>\n",
       "      <td>W460</td>\n",
       "      <td>3345</td>\n",
       "      <td>H616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA100007</td>\n",
       "      <td>K260</td>\n",
       "      <td>K600</td>\n",
       "      <td>L500</td>\n",
       "      <td>1225</td>\n",
       "      <td>G650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA100008</td>\n",
       "      <td>K536</td>\n",
       "      <td>J600</td>\n",
       "      <td>F652</td>\n",
       "      <td>4235</td>\n",
       "      <td>B645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>AB16955</td>\n",
       "      <td>W231</td>\n",
       "      <td>D242</td>\n",
       "      <td>R410</td>\n",
       "      <td>5325</td>\n",
       "      <td>T462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>AB16957</td>\n",
       "      <td>R163</td>\n",
       "      <td>C642</td>\n",
       "      <td>A636</td>\n",
       "      <td>1152</td>\n",
       "      <td>T462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>AB16959</td>\n",
       "      <td>B550</td>\n",
       "      <td>C645</td>\n",
       "      <td>D150</td>\n",
       "      <td>1155</td>\n",
       "      <td>T462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>AB16960</td>\n",
       "      <td>B530</td>\n",
       "      <td>L253</td>\n",
       "      <td>Y130</td>\n",
       "      <td>3246</td>\n",
       "      <td>T462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>AB16962</td>\n",
       "      <td>M421</td>\n",
       "      <td>K650</td>\n",
       "      <td>J525</td>\n",
       "      <td>7142</td>\n",
       "      <td>H353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1     2     3     4     5\n",
       "0      AA100000  B323  J520  A620  3523  G650\n",
       "1      AA100004  B620  M240  E421  2251  B645\n",
       "2      AA100006  B620  D520  W460  3345  H616\n",
       "3      AA100007  K260  K600  L500  1225  G650\n",
       "4      AA100008  K536  J600  F652  4235  B645\n",
       "...         ...   ...   ...   ...   ...   ...\n",
       "99995   AB16955  W231  D242  R410  5325  T462\n",
       "99996   AB16957  R163  C642  A636  1152  T462\n",
       "99997   AB16959  B550  C645  D150  1155  T462\n",
       "99998   AB16960  B530  L253  Y130  3246  T462\n",
       "99999   AB16962  M421  K650  J525  7142  H353\n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5885ff-1052-4cd8-be80-1633b0e1f399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproccess took 13.7715 seconds\n",
      "evaluate took 11634.1816 seconds\n",
      "calculateStatistics took 0.1742 seconds\n",
      "Expected: {}\n",
      "Ground Truth Size: 25000\n",
      "True Positives: 15636\n",
      "False Positives: 3318\n",
      "False Negatives: 9364\n",
      "Precision: 0.8249\n",
      "Recall: 0.6254\n"
     ]
    }
   ],
   "source": [
    " PATH  =  \"data/\"\n",
    "\n",
    "df1 = pd.read_csv(os.path.join(PATH, 'df1.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "df2 = pd.read_csv(os.path.join(PATH, 'df2.csv'), header=None)[[0,1,2,3,4,5]]\n",
    "\n",
    "# Run pipeline and see statistics\n",
    "pipeline = MyClass(df1.copy(), df2.copy(), matchColumn=0, on=[1,2,3,4,5], method=\"column\", threshold = 0.6) #  --> this means at least 3/5 of the fields must match \n",
    "pipeline.soundexDfs()\n",
    "\n",
    "evaluator = DatasetEvaluator(pipeline.df1.copy(), pipeline.df2.copy(), threshold=3, match_column=0)\n",
    "evaluator.preproccess()\n",
    "evaluator.evaluate()\n",
    "evaluator.calculateStatistics()\n",
    "evaluator.printResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "539ca657-83d1-4991-944e-6f3b2553bf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9879.75 //60//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e2c5e2-15a7-4438-b95f-dcc96b22783e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "30485.83 //60//60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a98fac-b2da-49ef-b2e7-de05e326fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 21180\n",
    "False Positives: 12559\n",
    "False Negatives: 3820\n",
    "Precision: 0.6278\n",
    "Recall: 0.8472\n",
    "Elapsed Time: 30485.83 seconds\n",
    "\n",
    "\n",
    "trim = 1\n",
    "preproccess took 28.2823 seconds\n",
    "evaluate took 17617.6667 seconds\n",
    "calculateStatistics took 0.5669 seconds\n",
    "Expected: {}\n",
    "Ground Truth Size: 25000\n",
    "True Positives: 21695\n",
    "False Positives: 18613\n",
    "False Negatives: 3305\n",
    "Precision: 0.5382\n",
    "Recall: 0.8678"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
