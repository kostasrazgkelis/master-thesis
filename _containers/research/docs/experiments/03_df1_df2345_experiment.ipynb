{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6318f8b7-ade2-409e-a22f-2808386cc530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish\n",
    "\n",
    "# DF1 vs DF2, DF3, DF4, DF5 Multi-Dataset Experiment\n",
    "\n",
    "# This experiment tests the entity matching pipeline using df1 as the left dataset and df2, df3, df4, df5 as the right datasets, demonstrating the multi-dataset matching capability.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Setup paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "from packages.pyspark.entity_matching_pipeline import run_entity_matching\n",
    "\n",
    "# Initialize Spark session with optimized configuration for larger datasets\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"DF1vsDF2345MultiExperiment\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "# Load all datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "def load_dataset(filename):\n",
    "    \"\"\"Helper function to load and standardize dataset format\"\"\"\n",
    "    return spark.read.csv(os.path.join(project_root, f\"data/{filename}\"), header=False, inferSchema=True) \\\n",
    "        .select(\"_c0\", \"_c1\", \"_c2\", \"_c3\", \"_c4\", \"_c5\") \\\n",
    "        .toDF(\"0\", \"1\", \"2\", \"3\", \"4\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b46eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 (left) size: 100000\n",
      "df2 size: 100000\n",
      "df3 size: 100000\n",
      "df4 size: 100000\n",
      "df5 size: 100000\n",
      "Total right dataset records: 400000\n",
      "Running multi-dataset entity matching pipeline...\n",
      "This will match df1 against the union of df2, df3, df4, and df5\n",
      "This may take several minutes depending on dataset sizes...\n",
      "Starting Multi-Dataset Entity Matching Pipeline...\n",
      "Processing 1 left dataset vs 4 right datasets\n",
      "Step 1: Preprocessing left dataframe...\n",
      "Step 1b: Preprocessing and union right dataframes...\n",
      "Unified right dataset has 400000 total records\n",
      "Step 2: Creating entity keys...\n",
      "Step 3: Calculating similarity matrix...\n",
      "Step 4: Applying similarity threshold...\n",
      "Step 5: Assigning entities to buckets...\n",
      "Step 6: Calculating ground truth...\n",
      "Step 7: Evaluating results...\n",
      "Multi-dataset pipeline completed successfully!\n",
      "\n",
      "Pipeline completed successfully!\n",
      "Multi-Dataset Matching Results:\n",
      "==================================================\n",
      "Total buckets created: 36882\n",
      "\n",
      "Top 10 largest buckets:\n",
      "+---------+-----------+------------------+\n",
      "|bucket_id|bucket_size|    avg_similarity|\n",
      "+---------+-----------+------------------+\n",
      "| AA122606|        134|0.6074626865671646|\n",
      "|  AA11304|        119|0.6050420168067231|\n",
      "| AA149080|        118|0.6033898305084751|\n",
      "| AA139446|        117|0.6068376068376071|\n",
      "| AA121107|        114|0.6035087719298249|\n",
      "| AA135775|        111|0.6072072072072077|\n",
      "| AA117145|        108|0.6074074074074076|\n",
      "| AA138494|        103|0.6077669902912627|\n",
      "| AA106151|        102|0.6078431372549022|\n",
      "| AA139847|         98|0.6122448979591841|\n",
      "+---------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "Evaluation Metrics:\n",
      "ground_truth: 25000\n",
      "true_positives: 24549\n",
      "false_positives: 12333\n",
      "false_negatives: 451\n",
      "precision: 0.6656092402798113\n",
      "recall: 0.98196\n",
      "f1_score: 0.7934132704178921\n",
      "total_buckets: 36882\n",
      "average_bucket_size: 4.092484138604197\n",
      "\n",
      "Performance Summary:\n",
      "Precision: 0.6656\n",
      "Recall: 0.9820\n",
      "F1-Score: 0.7934\n",
      "Average Bucket Size: 4.09\n",
      "\n",
      "Detailed Analysis:\n",
      "==================================================\n",
      "Bucket Size Statistics:\n",
      "  Min: 1\n",
      "  Max: 134\n",
      "  Mean: 4.09\n",
      "  Median: 2.00\n",
      "  Std Dev: 7.08\n",
      "\n",
      "Similarity Score Statistics:\n",
      "  Min: 0.6000\n",
      "  Max: 1.0000\n",
      "  Mean: 0.6779\n",
      "  Median: 0.6222\n",
      "\n",
      "Example buckets with assigned entities:\n",
      "+---------+------------------------------+-----------+--------------+\n",
      "|bucket_id|assigned_entities             |bucket_size|avg_similarity|\n",
      "+---------+------------------------------+-----------+--------------+\n",
      "|AA102272 |[AA102272, AA102272]          |2          |1.0           |\n",
      "|AA102465 |[AA102465, AA102465, AA102465]|3          |1.0           |\n",
      "|AA105678 |[AA105678, AA105678]          |2          |1.0           |\n",
      "|AA104001 |[AA104001, AA104001]          |2          |1.0           |\n",
      "|AA103035 |[AA103035, AA103035]          |2          |1.0           |\n",
      "+---------+------------------------------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load left dataset\n",
    "df1 = load_dataset(\"df1.csv\")\n",
    "\n",
    "# Load right datasets\n",
    "df2 = load_dataset(\"df2.csv\")\n",
    "df3 = load_dataset(\"df3.csv\")\n",
    "df4 = load_dataset(\"df4.csv\")\n",
    "df5 = load_dataset(\"df5.csv\")\n",
    "\n",
    "print(f\"df1 (left) size: {df1.count()}\")\n",
    "print(f\"df2 size: {df2.count()}\")\n",
    "print(f\"df3 size: {df3.count()}\")\n",
    "print(f\"df4 size: {df4.count()}\")\n",
    "print(f\"df5 size: {df5.count()}\")\n",
    "\n",
    "total_right_records = df2.count() + df3.count() + df4.count() + df5.count()\n",
    "print(f\"Total right dataset records: {total_right_records}\")\n",
    "\n",
    "# Run multi-dataset entity matching pipeline\n",
    "print(\"Running multi-dataset entity matching pipeline...\")\n",
    "print(\"This will match df1 against the union of df2, df3, df4, and df5\")\n",
    "\n",
    "buckets, metrics = run_entity_matching(\n",
    "    spark=spark,\n",
    "    left_df=df1,\n",
    "    right_dataframes=[df2, df3, df4, df5],\n",
    "    similarity_threshold=0.6,\n",
    "    min_matching_columns=3\n",
    ")\n",
    "\n",
    "print(\"\\nPipeline completed successfully!\")\n",
    "\n",
    "# Analyze results\n",
    "print(\"Multi-Dataset Matching Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"Total buckets created: {buckets.count()}\")\n",
    "\n",
    "# Show top buckets by size\n",
    "print(\"\\nTop 10 largest buckets:\")\n",
    "buckets.select(\"bucket_id\", \"bucket_size\", \"avg_similarity\") \\\n",
    "    .orderBy(F.desc(\"bucket_size\")) \\\n",
    "    .show(10)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nPerformance Summary:\")\n",
    "print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "print(f\"F1-Score: {metrics['f1_score']:.4f}\")\n",
    "print(f\"Average Bucket Size: {metrics['average_bucket_size']:.2f}\")\n",
    "\n",
    "\n",
    "# Additional analysis\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Bucket size distribution\n",
    "bucket_sizes = buckets.select(\"bucket_size\").rdd.map(lambda row: row[0]).collect()\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Bucket Size Statistics:\")\n",
    "print(f\"  Min: {min(bucket_sizes)}\")\n",
    "print(f\"  Max: {max(bucket_sizes)}\")\n",
    "print(f\"  Mean: {np.mean(bucket_sizes):.2f}\")\n",
    "print(f\"  Median: {np.median(bucket_sizes):.2f}\")\n",
    "print(f\"  Std Dev: {np.std(bucket_sizes):.2f}\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e94402-d929-4106-a279-da29f4f6fb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
