{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3db35b-9743-41fe-a5b5-47dcc53b0f68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in /opt/conda/lib/python3.11/site-packages (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "# Setup paths\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "from packages.pyspark.entity_matching_pipeline import run_entity_matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cdd8e3-68f0-4ccb-9d40-bbe5a5f1b374",
   "metadata": {
    "tags": []
   },
   "source": [
    "This experiment tests the refactored entity matching pipeline with a small synthetic dataset to verify basic functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebee0bfa-8bce-4b33-9dbd-e8261aa64ab9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create small synthetic datasets for testing\n",
    "# Data for df1\n",
    "data1 = [\n",
    "    [\"ID00005\", \"N039\", \"E298\", \"Q412\", \"V409\", \"R232\"],  # TP1\n",
    "    [\"ID00009\", \"R822\", \"W179\", \"H017\", \"P323\", \"F298\"],  # TP2\n",
    "    [\"ID00007\", \"R449\", \"X716\", \"M948\", \"G667\", \"S702\"],  # TP3\n",
    "    [\"ID00004\", \"N002\", \"E396\", \"N843\", \"I458\", \"S719\"],  # TP4\n",
    "    [\"ID10004\", \"N002\", \"E396\", \"N853\", \"I623\", \"S569\"],  # FN1\n",
    "    [\"ID50004\", \"J547\", \"B222\", \"G492\", \"R551\", \"S490\"],  # FP1\n",
    "    [\"IDTIE00\", \"N322\", \"K685\", \"T442\", \"C225\", \"W967\"],  # FP-tie: this should be skipped\n",
    "    [\"ID50008\", \"N322\", \"K685\", \"T442\", \"C225\", \"W967\"],  # FP2\n",
    "    [\"ID00000\", \"W815\", \"L281\", \"R155\", \"F768\", \"B914\"],\n",
    "    [\"ID00001\", \"C172\", \"B326\", \"X400\", \"M508\", \"O776\"],\n",
    "    [\"ID00002\", \"V683\", \"C265\", \"J127\", \"D589\", \"F482\"],\n",
    "    [\"ID00003\", \"E851\", \"P721\", \"F745\", \"D863\", \"K229\"],\n",
    "    [\"ID00016\", \"T873\", \"D670\", \"U046\", \"Z181\", \"X621\"],\n",
    "    [\"ID00017\", \"F327\", \"G856\", \"E567\", \"O929\", \"Q721\"],\n",
    "    [\"ID00010\", \"O283\", \"T723\", \"Z034\", \"V319\", \"X338\"],\n",
    "]\n",
    "\n",
    "# Data for df2\n",
    "data2 = [\n",
    "    [\"ID00005\", \"R746\", \"E298\", \"Q412\", \"L291\", \"R232\"],  # TP1\n",
    "    [\"ID00009\", \"R822\", \"W179\", \"H017\", \"P323\", \"F298\"],  # TP2\n",
    "    [\"ID00007\", \"Z011\", \"X716\", \"M948\", \"W967\", \"S702\"],  # TP3\n",
    "    [\"ID00004\", \"N002\", \"E396\", \"N843\", \"V935\", \"S719\"],  # TP4\n",
    "    [\"ID10004\", \"N002\", \"E396\", \"N553\", \"I453\", \"S459\"],  # FN1\n",
    "    [\"NEW80187\", \"J547\", \"B222\", \"G492\", \"W673\", \"S490\"],  # FP1\n",
    "    [\"NEW30110\", \"N322\", \"K685\", \"T432\", \"C225\", \"W967\"],  # FP2\n",
    "    [\"NEW72832\", \"F875\", \"Q768\", \"H822\", \"Z154\", \"X678\"],\n",
    "    [\"NEW30110\", \"R560\", \"C434\", \"M687\", \"Q689\", \"Q863\"],\n",
    "    [\"NEW81243\", \"R762\", \"N687\", \"A109\", \"K476\", \"R637\"],\n",
    "    [\"NEW52689\", \"A089\", \"V733\", \"W158\", \"A640\", \"H331\"],\n",
    "    [\"NEW67368\", \"Z079\", \"J617\", \"G878\", \"W111\", \"Q500\"],\n",
    "    [\"NEW72348\", \"J547\", \"B222\", \"G492\", \"R551\", \"S490\"],\n",
    "    [\"NEW34469\", \"Y990\", \"H898\", \"W673\", \"L967\", \"M829\"],\n",
    "    [\"NEW34462\", \"Y990\", \"H898\", \"W673\", \"L967\", \"M829\"],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ad4b3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1 (Left dataset):\n",
      "+-------+----+----+----+----+----+\n",
      "|      0|   1|   2|   3|   4|   5|\n",
      "+-------+----+----+----+----+----+\n",
      "|ID00005|N039|E298|Q412|V409|R232|\n",
      "|ID00009|R822|W179|H017|P323|F298|\n",
      "|ID00007|R449|X716|M948|G667|S702|\n",
      "|ID00004|N002|E396|N843|I458|S719|\n",
      "|ID10004|N002|E396|N853|I623|S569|\n",
      "|ID50004|J547|B222|G492|R551|S490|\n",
      "|IDTIE00|N322|K685|T442|C225|W967|\n",
      "|ID50008|N322|K685|T442|C225|W967|\n",
      "|ID00000|W815|L281|R155|F768|B914|\n",
      "|ID00001|C172|B326|X400|M508|O776|\n",
      "|ID00002|V683|C265|J127|D589|F482|\n",
      "|ID00003|E851|P721|F745|D863|K229|\n",
      "|ID00016|T873|D670|U046|Z181|X621|\n",
      "|ID00017|F327|G856|E567|O929|Q721|\n",
      "|ID00010|O283|T723|Z034|V319|X338|\n",
      "+-------+----+----+----+----+----+\n",
      "\n",
      "df2 (Right dataset):\n",
      "+--------+----+----+----+----+----+\n",
      "|       0|   1|   2|   3|   4|   5|\n",
      "+--------+----+----+----+----+----+\n",
      "| ID00005|R746|E298|Q412|L291|R232|\n",
      "| ID00009|R822|W179|H017|P323|F298|\n",
      "| ID00007|Z011|X716|M948|W967|S702|\n",
      "| ID00004|N002|E396|N843|V935|S719|\n",
      "| ID10004|N002|E396|N553|I453|S459|\n",
      "|NEW80187|J547|B222|G492|W673|S490|\n",
      "|NEW30110|N322|K685|T432|C225|W967|\n",
      "|NEW72832|F875|Q768|H822|Z154|X678|\n",
      "|NEW30110|R560|C434|M687|Q689|Q863|\n",
      "|NEW81243|R762|N687|A109|K476|R637|\n",
      "|NEW52689|A089|V733|W158|A640|H331|\n",
      "|NEW67368|Z079|J617|G878|W111|Q500|\n",
      "|NEW72348|J547|B222|G492|R551|S490|\n",
      "|NEW34469|Y990|H898|W673|L967|M829|\n",
      "|NEW34462|Y990|H898|W673|L967|M829|\n",
      "+--------+----+----+----+----+----+\n",
      "\n",
      "Running entity matching pipeline...\n",
      "Starting Multi-Dataset Entity Matching Pipeline...\n",
      "Processing 1 left dataset vs 1 right datasets\n",
      "Step 1: Preprocessing left dataframe...\n",
      "Step 1b: Preprocessing and union right dataframes...\n",
      "Unified right dataset has 15 total records\n",
      "Step 2: Creating entity keys...\n",
      "Step 3: Calculating similarity matrix...\n",
      "Step 4: Applying similarity threshold...\n",
      "Step 5: Assigning entities to buckets...\n",
      "Step 6: Calculating ground truth...\n",
      "Step 7: Evaluating results...\n",
      "Multi-dataset pipeline completed successfully!\n",
      "\n",
      "Buckets (Matching Results):\n",
      "+---------+------------------+--------------+-----------+\n",
      "|bucket_id| assigned_entities|avg_similarity|bucket_size|\n",
      "+---------+------------------+--------------+-----------+\n",
      "|  ID00004|         [ID00005]|           0.6|          1|\n",
      "| NEW30110|[ID50008, IDTIE00]|           1.0|          2|\n",
      "|  ID10004|[ID00004, ID10004]|           1.0|          2|\n",
      "|  ID00009|         [ID00009]|           1.0|          1|\n",
      "| NEW72348|         [ID50004]|           1.0|          1|\n",
      "|  ID00005|         [ID00005]|           0.6|          1|\n",
      "|  ID00007|         [ID00007]|           0.6|          1|\n",
      "+---------+------------------+--------------+-----------+\n",
      "\n",
      "\n",
      "Evaluation Metrics:\n",
      "ground_truth: 5\n",
      "true_positives: 4\n",
      "false_positives: 3\n",
      "false_negatives: 1\n",
      "precision: 0.5714285714285714\n",
      "recall: 0.8\n",
      "f1_score: 0.6666666666666666\n",
      "total_buckets: 7\n",
      "average_bucket_size: 1.2857142857142858\n",
      "\n",
      "Expected Results Analysis:\n",
      "- Ground truth matches: 4 (ID00005, ID00009, ID00007, ID00004)\n",
      "- Expected True Positives: 4\n",
      "- Expected False Positives: 3\n",
      "- Expected False Negatives: 1\n",
      "- Expected Precision: 0.5714285714285714\n",
      "- Expected Recall: 0.8\n",
      "- Expected F1-Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"SmallSampleExperiment\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Convert to Spark DataFrames\n",
    "df1 = spark.createDataFrame(data1, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "df2 = spark.createDataFrame(data2, [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "\n",
    "print(\"df1 (Left dataset):\")\n",
    "df1.show()\n",
    "print(\"df2 (Right dataset):\")\n",
    "df2.show()\n",
    "\n",
    "\n",
    "# Run entity matching pipeline\n",
    "print(\"Running entity matching pipeline...\")\n",
    "buckets, metrics = run_entity_matching(\n",
    "    spark=spark,\n",
    "    left_df=df1,\n",
    "    right_dataframes=[df2],\n",
    "    similarity_threshold=0.6,\n",
    "    min_matching_columns=3\n",
    ")\n",
    "\n",
    "print(\"\\nBuckets (Matching Results):\")\n",
    "buckets.show()\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "    \n",
    "# Expected results analysis\n",
    "print(\"\\nExpected Results Analysis:\")\n",
    "print(\"- Ground truth matches: 4 (ID00005, ID00009, ID00007, ID00004)\")\n",
    "print(\"- Expected True Positives: 4\")\n",
    "print(\"- Expected False Positives: 3\")\n",
    "print(\"- Expected False Negatives: 1\")\n",
    "print(\"- Expected Precision: 0.5714285714285714\")\n",
    "print(\"- Expected Recall: 0.8\")\n",
    "print(\"- Expected F1-Score: 0.6666666666666666\")\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
